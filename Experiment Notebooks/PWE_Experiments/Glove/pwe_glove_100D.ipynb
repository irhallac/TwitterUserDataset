{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/ibrahim/.conda/envs/py37irh/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Check this path\n",
    "pwe_path = \"DATASTORE/PWEs/glove/glove.6B.100d.w2vformat.txt\"\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(pwe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/ibrahim/.conda/envs/py37irh/bin/python\n"
     ]
    }
   ],
   "source": [
    "#Import all  dependencies\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime \n",
    "from scipy import spatial\n",
    "#result = 1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "here = os.getcwd()\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "from reviewFunctions import user2vec_test\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=\"glove6B_new.log\",\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.CRITICAL)\n",
    "\n",
    "logging.critical(\"\\n PWE Experiment 3: Tweet embedding with Average Glove2(tweet) PWE - Train and Test Splitted %60 and %40\")\n",
    "logger = logging.getLogger('glove6B_new')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#saveJson(path_prefix, user_vecs, ctg_vecs, self.epoch) changedd\n",
    "def saveJson(path_prefix, user_vecs_test, ctg_vecs_train, user_vecs_train, epoch):\n",
    "    logging.critical(\"saveJSon started\")\n",
    "    path = get_tmpfile('{}/embeddings/users_test{}.json'.format(path_prefix,epoch))\n",
    "    with open(path, 'w') as outfile:\n",
    "        json.dump(user_vecs_test, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    path = get_tmpfile('{}/embeddings/categories_train{}.json'.format(path_prefix,epoch))\n",
    "    with open(path, 'w') as outfile:\n",
    "        json.dump(ctg_vecs_train, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    path = get_tmpfile('{}/embeddings/users_train{}.json'.format(path_prefix,epoch))\n",
    "    with open(path, 'w') as outfile:\n",
    "        json.dump(user_vecs_train, outfile)\n",
    "    outfile.close()\n",
    "    logging.critical(\"saveJSon finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc\n",
    "\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)\n",
    "\n",
    "def get_user_dataframe(path):\n",
    "    dataFrames = []\n",
    "    for folder in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, folder)):\n",
    "            print(\"folder: \", folder)\n",
    "            for file_name in os.listdir(os.path.join(path, folder)):\n",
    "                if file_name.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(path, folder, file_name)\n",
    "                    df = pd.read_csv(file_path,header=None,usecols=[3,0,2], \n",
    "                                     names=['tweet_id', 'date', 'user_name', 'text'])\n",
    "                    df = df.astype(str)\n",
    "                    df[\"category\"] = folder\n",
    "                    dataFrames.append(df)\n",
    "\n",
    "    dfs = pd.concat(dataFrames)\n",
    "    print(\"total \", len(dfs), \" tweets\")\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iter_acc(model, dfs_train, dfs_test):\n",
    "    # creaa\n",
    "    user_vecs_train = {}\n",
    "    ctg_vecs_train = {}\n",
    "    user_vecs_test = {}\n",
    "  \n",
    "    logging.critical(\"beginning: of calc_iter_acc\")\n",
    "    logging.critical(\"first: inferring user_vecs_train\")\n",
    "    for index, datapoint in dfs_train.iterrows():\n",
    "        unname = datapoint[\"user_name\"]\n",
    "        tid = datapoint[\"tweet_id\"]\n",
    "        category = datapoint[\"category\"]\n",
    "        tokenized_words = preprocess(datapoint[\"text\"])      \n",
    "        if has_vector_representation(model, tokenized_words):\n",
    "            vec = document_vector(model, tokenized_words)         \n",
    "            if unname in user_vecs_train.keys():\n",
    "                user_vecs_train[unname][\"vecs\"].append(vec)\n",
    "            else:\n",
    "                user_vecs_train[unname] = {\"vecs\": [vec], \"category\": category}\n",
    "\n",
    "    # find the average of tweet vectors for each user\n",
    "    for unm in user_vecs_train.keys():\n",
    "        user_vecs_train[unm][\"avr_vec\"] = np.average(np.array(user_vecs_train[unm][\"vecs\"]), axis=0)              \n",
    "      \n",
    "    #\n",
    "    logging.critical(\"second: inferring user_vecs_test\")\n",
    "    for index, datapoint in dfs_test.iterrows():\n",
    "        unname = datapoint[\"user_name\"]\n",
    "        tid = datapoint[\"tweet_id\"]\n",
    "        category = datapoint[\"category\"]\n",
    "        tokenized_words = preprocess(datapoint[\"text\"])\n",
    "        if has_vector_representation(model, tokenized_words):\n",
    "            vec = document_vector(model, tokenized_words)       \n",
    "            if unname in user_vecs_test.keys():\n",
    "                user_vecs_test[unname][\"vecs\"].append(vec)\n",
    "            else:\n",
    "                user_vecs_test[unname] = {\"vecs\": [vec], \"category\": category}\n",
    "\n",
    "    # find the average of tweet vectors for each user, dfs_test\n",
    "    for unm in user_vecs_test.keys():\n",
    "        user_vecs_test[unm][\"avr_vec\"] = np.average(np.array(user_vecs_test[unm][\"vecs\"]), axis=0)\n",
    "    #\n",
    "    \n",
    "    # create category vector dictionary\n",
    "    for unm in user_vecs_train.keys():\n",
    "        avg = user_vecs_train[unm][\"avr_vec\"]\n",
    "        ctg = user_vecs_train[unm][\"category\"]\n",
    "        if ctg in ctg_vecs_train.keys():\n",
    "            ctg_vecs_train[ctg][\"cat_vecs\"].append(avg)\n",
    "        else:\n",
    "            ctg_vecs_train[ctg] = {\"cat_vecs\": [avg]}\n",
    "\n",
    "    # find the average of category vectors\n",
    "    for ctg in ctg_vecs_train.keys():\n",
    "        ctg_vecs_train[ctg][\"avr_cat_vec\"] = np.average(np.array(ctg_vecs_train[ctg][\"cat_vecs\"]), axis=0)  \n",
    "    \n",
    "    users_test = {}\n",
    "    for usr in user_vecs_test.keys():\n",
    "        users_test[usr] = {'avr_vec' : user_vecs_test[usr][\"avr_vec\"].tolist(), 'category': user_vecs_test[usr][\"category\"]}\n",
    "\n",
    "    users_train = {}\n",
    "    for usr in user_vecs_train.keys():\n",
    "        users_train[usr] = {'avr_vec' : user_vecs_train[usr][\"avr_vec\"].tolist(), 'category': user_vecs_train[usr][\"category\"]}        \n",
    "    \n",
    "    categories_train = {}\n",
    "    for ctg in ctg_vecs_train.keys():\n",
    "        categories_train[ctg] = {'avr_cat_vec' : ctg_vecs_train[ctg][\"avr_cat_vec\"].tolist()}\n",
    "\n",
    "    #update here\n",
    "    logging.critical(\"end of: calc_iter_acc\")\n",
    "    uvt = user2vec_test(user_vecs=users_test, ctg_vecs=categories_train) # test model\n",
    "    msg1 = uvt.calc_accuracy()\n",
    "    print(msg1)\n",
    "    logging.critical(msg1)\n",
    "    msg2 = uvt.calc_accuracy_by_group()\n",
    "    print(msg2)\n",
    "    logging.critical(msg2)\n",
    "   \n",
    "    #conf matrix\n",
    "    true_labels = []\n",
    "    predicted_labes = []\n",
    "\n",
    "    for unm in uvt.user_vecs.keys():\n",
    "        true_labels.append(uvt.getUserCategory(unm))\n",
    "        predicted_labes.append(uvt.most_similar_group(unm))\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    msg3 = metrics.confusion_matrix(true_labels, predicted_labes)\n",
    "    print(msg3)\n",
    "    logging.critical(msg3)\n",
    "\n",
    "    # Print the precision and recall, among other metrics\n",
    "    msg4 = metrics.classification_report(true_labels, predicted_labes, digits=3)\n",
    "    print(msg4)\n",
    "    logging.critical(msg4)    \n",
    "    \n",
    "    path_prefix = os.getcwd()\n",
    "    epoch = 0\n",
    "    saveJson(path_prefix, users_test, categories_train, users_train,epoch)\n",
    "    logging.critical(\"end of: calc_iter_acc\")\n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder:  twcollector3\n",
      "folder:  twcollector5\n",
      "folder:  twcollector1\n",
      "folder:  twcollector2\n",
      "folder:  twcollector4\n",
      "total  300000  tweets\n",
      "folder:  twcollector3\n",
      "folder:  twcollector5\n",
      "folder:  twcollector1\n",
      "folder:  twcollector2\n",
      "folder:  twcollector4\n",
      "total  200000  tweets\n"
     ]
    }
   ],
   "source": [
    "# # Check paths\n",
    "path_train = \"DATASTORE/DatasetA/train\"\n",
    "path_test = \"DATASTORE/DatasetA/test\"\n",
    "\n",
    "dfs_train = get_user_dataframe(path_train)\n",
    "dfs_test = get_user_dataframe(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Acc is 167/200 = 0.835\n",
      "\n",
      "overall acc. how many users are closest to their group \n",
      " twcollector3 38/40 Acc 0.95\n",
      "twcollector5 39/40 Acc 0.975\n",
      "twcollector1 24/40 Acc 0.6\n",
      "twcollector2 28/40 Acc 0.7\n",
      "twcollector4 38/40 Acc 0.95\n",
      "\n",
      "\n",
      "[[24  7  1  2  6]\n",
      " [ 5 28  5  1  1]\n",
      " [ 0  0 38  1  1]\n",
      " [ 0  1  1 38  0]\n",
      " [ 0  0  0  1 39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "twcollector1      0.828     0.600     0.696        40\n",
      "twcollector2      0.778     0.700     0.737        40\n",
      "twcollector3      0.844     0.950     0.894        40\n",
      "twcollector4      0.884     0.950     0.916        40\n",
      "twcollector5      0.830     0.975     0.897        40\n",
      "\n",
      "    accuracy                          0.835       200\n",
      "   macro avg      0.833     0.835     0.828       200\n",
      "weighted avg      0.833     0.835     0.828       200\n",
      "\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "print(calc_iter_acc(model, dfs_train, dfs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
